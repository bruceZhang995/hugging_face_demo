# å®‰è£…æ ¸å¿ƒåº“ï¼ˆæœ€æ–°ç‰ˆï¼‰
# !pip install transformers gradio torch
import os
import torch
os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'  # ç¦ç”¨ç¬¦å·é“¾æ¥è­¦å‘Š
import gradio as gr
from transformers import pipeline
from opencc import OpenCC  # ç”¨äºç®€ç¹è½¬æ¢
from transformers import pipeline, GPT2Tokenizer, GPT2LMHeadModel, BertTokenizer, AutoModelForCausalLM,AutoTokenizer
from transformers import BlipForConditionalGeneration, BlipProcessor
from PIL import Image
import requests
from io import BytesIO

### pipelineæ”¯æŒçš„task
"""
"audio-classification": will return a [`AudioClassificationPipeline`].
"automatic-speech-recognition": will return a [`AutomaticSpeechRecognitionPipeline`].
"conversational": will return a [`ConversationalPipeline`].
"depth-estimation": will return a [`DepthEstimationPipeline`].
"document-question-answering": will return a [`DocumentQuestionAnsweringPipeline`].
"feature-extraction": will return a [`FeatureExtractionPipeline`].
"fill-mask": will return a [`FillMaskPipeline`]:.
"image-classification": will return a [`ImageClassificationPipeline`].
"image-feature-extraction": will return an [`ImageFeatureExtractionPipeline`].
"image-segmentation": will return a [`ImageSegmentationPipeline`].
"image-to-image": will return a [`ImageToImagePipeline`].
"image-to-text": will return a [`ImageToTextPipeline`].
"mask-generation": will return a [`MaskGenerationPipeline`].
"object-detection": will return a [`ObjectDetectionPipeline`].
"question-answering": will return a [`QuestionAnsweringPipeline`].
"summarization": will return a [`SummarizationPipeline`].
"table-question-answering": will return a [`TableQuestionAnsweringPipeline`].
"text2text-generation": will return a [`Text2TextGenerationPipeline`].
"text-classification"` (alias `"sentiment-analysis"` available): will return a [`TextClassificationPipeline`].
"text-generation": will return a [`TextGenerationPipeline`]:.
"text-to-audio"` (alias `"text-to-speech"` available): will return a [`TextToAudioPipeline`]:.
"token-classification"` (alias `"ner"` available): will return a [`TokenClassificationPipeline`].
"translation": will return a [`TranslationPipeline`].
"translation_xx_to_yy": will return a [`TranslationPipeline`].
"video-classification": will return a [`VideoClassificationPipeline`].
"visual-question-answering": will return a [`VisualQuestionAnsweringPipeline`].
"zero-shot-classification": will return a [`ZeroShotClassificationPipeline`].
"zero-shot-image-classification": will return a [`ZeroShotImageClassificationPipeline`].
"zero-shot-audio-classification": will return a [`ZeroShotAudioClassificationPipeline`].
"zero-shot-object-detection": will return a [`ZeroShotObjectDetectionPipeline`].
"""

# ç®€ç¹è½¬æ¢å™¨
cc = OpenCC('t2s')  # ç¹ä½“è½¬ç®€ä½“

# 1. åˆ›å»ºç”Ÿæˆå™¨
## æ–‡æœ¬ç”Ÿæˆæ¨¡å‹
text_model_path = r"./models/gpt2-chinese-cluecorpussmall"
text_model = AutoModelForCausalLM.from_pretrained(text_model_path)
text_tokenizer = AutoTokenizer.from_pretrained(text_model_path)
text_generator = pipeline('text-generation', model=text_model,tokenizer=text_tokenizer, device=0)
print("åŠ è½½æˆåŠŸ!")

# 2. åŠ è½½å¤šæ¨¡æ€æ¨¡å‹ï¼ˆBLIPå›¾åƒæè¿°ç”Ÿæˆï¼‰
blip_model_path = r"./models/blip-image-caption-base"
blip_model_path = r"./models/Taiyi_BLIP-Chinese"
blip_processor = BlipProcessor.from_pretrained(blip_model_path)
blip_model = BlipForConditionalGeneration.from_pretrained(blip_model_path).to("cuda")
print("å¤šæ¨¡æ€æ¨¡å‹åŠ è½½æˆåŠŸ!")



# 3. å¤šæ¨¡æ€ç”Ÿæˆå‡½æ•°
def generate_multimodal(prompt, image, max_length=150, temperature=0.7, top_p=0.9, repetition_penalty=1.5,
                        mode="text_only"):
    try:
        # æ¨¡å¼é€‰æ‹©
        if mode == "text_only" or image is None:
            # çº¯æ–‡æœ¬ç”Ÿæˆ
            params = {
                "max_length": int(max_length),
                "num_return_sequences": 1,
                "temperature": float(temperature),
                "top_k": 50,
                "top_p": float(top_p),
                "repetition_penalty": float(repetition_penalty),
                "do_sample": True,
            }
            result = text_generator(prompt, **params)[0]['generated_text']
            ##ç®€ä¸­è½¬ç¹ä¸­
            simplified_result = cc.convert(result)
            return simplified_result

        elif mode == "image_caption":
            # å›¾åƒæè¿°ç”Ÿæˆ
            inputs = blip_processor(image, prompt, return_tensors="pt").to("cuda")
            outputs = blip_model.generate(**inputs, max_new_tokens=int(max_length))
            caption = blip_processor.decode(outputs[0], skip_special_tokens=True)
            ##ç®€ä¸­è½¬ç¹ä¸­
            simplified_result = cc.convert(caption)
            return simplified_result

        elif mode == "multimodal_story":
            # å¤šæ¨¡æ€æ•…äº‹ç”Ÿæˆï¼šå…ˆè·å–å›¾åƒæè¿°ï¼Œå†åŸºäºæè¿°ç”Ÿæˆæ•…äº‹
            # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆå›¾åƒæè¿°
            inputs = blip_processor(image, "", return_tensors="pt").to("cuda")
            outputs = blip_model.generate(**inputs, max_new_tokens=50)
            image_description = blip_processor.decode(outputs[0], skip_special_tokens=True)

            # ç¬¬äºŒæ­¥ï¼šåŸºäºæè¿°å’Œæç¤ºç”Ÿæˆæ•…äº‹
            combined_prompt = f"å›¾ç‰‡æè¿°: {image_description}\nç”¨æˆ·æç¤º: {prompt}\næ•…äº‹:"

            story_params = {
                "max_length": int(max_length),
                "temperature": float(temperature),
                "top_p": float(top_p),
                "repetition_penalty": float(repetition_penalty),
                "do_sample": True,
            }
            story = text_generator(combined_prompt, **story_params)[0]['generated_text']
            ##ç®€ä¸­è½¬ç¹ä¸­
            simplified_result = cc.convert(f"å›¾åƒæè¿°: {image_description}\n\nç”Ÿæˆæ•…äº‹:\n{story}")
            return simplified_result
            # è¿”å›å®Œæ•´ç»“æœï¼ˆåŒ…å«æè¿°å’Œæ•…äº‹ï¼‰
            # return cc.convert(f"å›¾åƒæè¿°: {image_description}\n\nç”Ÿæˆæ•…äº‹:\n{story}")

    except Exception as e:
        return f"ç”Ÿæˆå¤±è´¥: {str(e)}"

# 4. ä¸‹è½½ç¤ºä¾‹å›¾ç‰‡çš„å‡½æ•°
def download_image(url):
    try:
        response = requests.get(url)
        return Image.open(BytesIO(response.content))
    except:
        return None

def generate_text(prompt, max_length=150, temperature=0.7, top_p=0.9, repetition_penalty=1.5):
    """
        temperature         0.5 - 0.9       å€¼è¶Šé«˜è¶Šå¤©é©¬è¡Œç©ºï¼Œå€¼è¶Šä½è¶Šä¿å®ˆ
        top_p               0.85 - 0.95     åªè€ƒè™‘æ¦‚ç‡ç´¯ç§¯è¾¾é˜ˆå€¼çš„è¯æ±‡
        repetition_penalty  1.2 - 2.0       æœ‰æ•ˆé¿å…é‡å¤çŸ­è¯­
        max_length          80 - 200        æ ¹æ®éœ€æ±‚è°ƒæ•´è¾“å‡ºé•¿åº¦
    """
    params = {
        "max_length": int(max_length),  # é•¿åº¦ï¼ˆ50-200ä¹‹é—´ï¼‰
        "num_return_sequences":1,       # å›ºå®šç”Ÿæˆ1ä¸ªç»“æœ
        "temperature": float(temperature),      # æ§åˆ¶éšæœºæ€§ï¼š0.3-0.9ï¼ˆå€¼è¶Šä½è¶Šä¿å®ˆï¼‰
        "top_k": 50,            # æ ¸é‡‡æ ·ï¼ˆè¿‡æ»¤ä½æ¦‚ç‡è¯ï¼‰; å›ºå®šå€¼
        "top_p": float(top_p),  # é™åˆ¶å€™é€‰è¯æ•°é‡
        "repetition_penalty": float(repetition_penalty), # æŠ‘åˆ¶é‡å¤ï¼ˆ>1.0ç”Ÿæ•ˆï¼‰
        "do_sample":True,       # å¿…é¡»å¼€å¯é‡‡æ ·æ¨¡å¼
    }
    try:
        result = text_generator(prompt, **params)[0]['generated_text']
        # ç®€ç¹è½¬æ¢ï¼ˆç¡®ä¿è¾“å‡ºç®€ä½“ä¸­æ–‡ï¼‰
        simplified_result = cc.convert(result)
        return simplified_result
    except Exception as e:
        return f"ç”Ÿæˆå¤±è´¥: {str(e)}"


def main():
    # ç¤ºä¾‹å›¾ç‰‡URL
    example_images = [
        r"resource/Bao-0000.jpg",
        r"resource/Bao-0001.jpg",
        r"resource/Bao-0002.jpg",
        r"resource/Bao-0003.jpg",
        r"resource/Bao-0004.jpg",
        r"resource/Bao-0005.jpg",
        r"resource/Bao-0006.jpg",
        r"resource/Bao-0007.jpg",
        r"resource/Bao-0008.jpg",
        r"resource/Bao-0009.jpg",
    ]

    with gr.Blocks(title="å¤šæ¨¡æ€AIåˆ›ä½œå®éªŒå®¤") as demo:
        gr.Markdown("## ğŸ¨ å¤šæ¨¡æ€åˆ›ä½œå·¥ä½œå° - æ–‡æœ¬ä¸å›¾åƒè”åˆç”Ÿæˆ")

        with gr.Row():
            # å·¦ä¾§ï¼šè¾“å…¥åŒº
            with gr.Column(scale=1):
                mode_radio = gr.Radio(
                    choices=["text_only", "image_caption", "multimodal_story"],
                    value="text_only",
                    label="åˆ›ä½œæ¨¡å¼",
                    info="é€‰æ‹©ç”Ÿæˆæ¨¡å¼"
                )

                prompt_input = gr.Textbox(
                    label="è¾“å…¥æç¤º",
                    placeholder="åœ¨è¿™é‡Œè¾“å…¥ä½ çš„åˆ›æ„å¼€å¤´...",
                    lines=3
                )

                image_input = gr.Image(
                    type="pil",
                    label="ä¸Šä¼ å›¾ç‰‡",
                    interactive=True
                )

                with gr.Accordion("é«˜çº§å‚æ•°", open=False):
                    max_length_slider = gr.Slider(
                        minimum=50, maximum=300, value=150, step=10,
                        label="ç”Ÿæˆé•¿åº¦", interactive=True
                    )
                    temperature_slider = gr.Slider(
                        minimum=0.1, maximum=1.0, value=0.7, step=0.1,
                        label="éšæœºæ€§ (temperature)", interactive=True
                    )
                    top_p_slider = gr.Slider(
                        minimum=0.5, maximum=1.0, value=0.9, step=0.05,
                        label="å¤šæ ·æ€§ (top-p)", interactive=True
                    )
                    repetition_penalty_slider = gr.Slider(
                        minimum=1.0, maximum=2.0, value=1.2, step=0.1,
                        label="é˜²é‡å¤æƒ©ç½š", interactive=True
                    )

                generate_btn = gr.Button("å¼€å§‹åˆ›ä½œ", variant="primary")

            # å³ä¾§ï¼šè¾“å‡ºåŒº
            with gr.Column(scale=2):
                output_text = gr.Textbox(
                    label="åˆ›ä½œç»“æœ",
                    interactive=False,
                    lines=12,
                    show_copy_button=True
                )
                gr.Markdown("### æ¨¡å¼è¯´æ˜:")
                gr.Markdown("- **çº¯æ–‡æœ¬æ¨¡å¼**: ä»…åŸºäºæ–‡æœ¬æç¤ºç”Ÿæˆå†…å®¹")
                gr.Markdown("- **å›¾åƒæè¿°æ¨¡å¼**: æ ¹æ®å›¾ç‰‡ç”Ÿæˆæè¿°æ–‡å­—")
                gr.Markdown("- **å¤šæ¨¡æ€æ•…äº‹æ¨¡å¼**: ç»“åˆå›¾ç‰‡å’Œæç¤ºç”Ÿæˆåˆ›æ„æ•…äº‹")

        # ç¤ºä¾‹åŒº
        with gr.Row():
            gr.Examples(
                examples=[
                    ["æœªæ¥ä¸–ç•Œï¼Œæœºå™¨äººæ‹¥æœ‰äº†æƒ…æ„Ÿï¼Œä»–ä»¬", None, "text_only"],
                    ["æè¿°è¿™å¼ å›¾ç‰‡ä¸­çš„åœºæ™¯", example_images[0], "image_caption"],
                    ["æ ¹æ®å›¾ç‰‡ç¼–ä¸€ä¸ªç§‘å¹»æ•…äº‹", example_images[2], "multimodal_story"]
                ],
                inputs=[prompt_input, image_input, mode_radio],
                label="å°è¯•è¿™äº›ç¤ºä¾‹",
                examples_per_page=3
            )

        # ç»‘å®šæŒ‰é’®äº‹ä»¶
        generate_btn.click(
            fn=generate_multimodal,
            inputs=[
                prompt_input,
                image_input,
                max_length_slider,
                temperature_slider,
                top_p_slider,
                repetition_penalty_slider,
                mode_radio
            ],
            outputs=output_text
        )

    # å®‰å…¨å¯åŠ¨ï¼ˆè‡ªåŠ¨ç«¯å£æ£€æµ‹ï¼‰
    port = 7860
    while port < 8000:
        try:
            demo.launch(server_name="127.0.0.1", server_port=port)
            print(f"æˆåŠŸå¯åŠ¨åœ¨ç«¯å£: {port}")
            break
        except:
            print(f"ç«¯å£ {port} è¢«å ç”¨ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
            port += 1
    return

if __name__ == '__main__':
    main()